{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test that linear response theory is recovering the true amplification of freshwater fluxes, we need to evaluate the amplification of fluxes from CESM flux fields. Note that as linear response theory is finding the change in freshwater fluxes as a proportion of the FAFMIP perturbation, the truth is not exactly the change in magnitude of freshwater fluxes. Here we show the test with the integration metric defined in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import netCDF4\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import os, glob \n",
    "import imageio\n",
    "from matplotlib import animation\n",
    "import copy\n",
    "import cartopy as cart\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter #see https://scitools.org.uk/cartopy/docs/v0.15/examples/tick_labels.html\n",
    "import certifi\n",
    "import ssl\n",
    "import math\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "from scipy import stats\n",
    "from xgcm import Grid\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.axes._secondary_axes import SecondaryAxis\n",
    "import xesmf as xe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, load in all the freshwater fluxes. See notebook processing_salt_fluxes.py for how to generate this files that we unpickle here\n",
    "import pickle \n",
    "\n",
    "with open(\"/scratch/abf376/regridded_salt_flux_2005on\", \"rb\") as fp:   #Unpickling\n",
    "    regridded_2005on=pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First we calculate the true fluxes for the ensemble mean using the integration metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average over ensemble member\n",
    "salt_flux_avg_2005on=sum(regridded_2005on)/34\n",
    "salt_flux_avg_2005on=salt_flux_avg_2005on.rename({'y': 'latitude','x': 'longitude'})\n",
    "salt_flux_avg_2005on=salt_flux_avg_2005on.assign_coords(latitude=salt_flux_avg_2005on.lat[:,0],longitude=salt_flux_avg_2005on.lon[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "salt_flux_avg_2006to2055=salt_flux_avg_2005on[0:12*59,:,:] #salt_avg was from 1920 to 2080 so this is from 1970 to 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create area grid\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '/scratch/abf376/')\n",
    "from area_grid import *\n",
    "\n",
    "area=area_grid(latitudes=np.array(salt_flux_avg_2005on[0,:,:].latitude),longitudes=salt_flux_avg_2005on[0,:,:].longitude)\n",
    "area=xr.DataArray(area,dims=[\"latitude\",\"longitude\"],coords=[salt_flux_avg_2005on[0,:,:].latitude,salt_flux_avg_2005on[0,:,:].longitude])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#water flux from fafmip\n",
    "f='/scratch/abf376/FAFMIP_wfo_v2.nc' #this is the first 50 years\n",
    "file2read = netCDF4.Dataset(f,'r')\n",
    "#print(file2read.variables)\n",
    "wfo = xr.open_dataset(f)['water_flux_into_sea_water']\n",
    "wfo=wfo.where(wfo<1E19)\n",
    "\n",
    "\n",
    "area_wfo=area_grid(latitudes=np.array(wfo.latitude),longitudes=wfo.longitude)\n",
    "area_wfo=xr.DataArray(area,dims=[\"latitude\",\"longitude\"],coords=[wfo.latitude,wfo.longitude])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/lib/python3.9/site-packages/xarray/core/dataarray.py:780: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return key in self.data\n"
     ]
    }
   ],
   "source": [
    "#regrid wfo\n",
    "ds_out = xe.util.grid_global(1, 1)\n",
    "regridder_wfo= xe.Regridder(wfo, ds_out, \"bilinear\",periodic=True)\n",
    "wfo = regridder_wfo(wfo)\n",
    "wfo=wfo.rename({'y': 'latitude','x': 'longitude'})\n",
    "wfo=wfo.assign_coords(latitude=wfo.lat[:,0],longitude=wfo.lon[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EP_pattern_wfo=np.empty(50)\n",
    "for i in range(0,50):\n",
    "    EP_pattern_wfo[i]=np.abs((((salt_flux_avg_2006to2055[i*12:(i+1)*12,:,:].mean('time')).where(np.sign(wfo.mean('time'))>0))*area.where(area.latitude<65)).sum())+np.abs((((salt_flux_avg_2006to2055[i*12:(i+1)*12,:,:].mean('time')).where(np.sign(wfo.mean('time'))<0))*area.where(area.latitude<65)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.338997043114277e-01\n",
      "0.04939843236937896\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "A=((np.abs(wfo.mean('time')))*area.where(area.latitude<65)).sum() #strength of wfo in this way, 9.99660706e+08 if calculated with regridded or 1.08156723e+09 if not calculated with regridded\n",
    "\n",
    "\n",
    "change2=np.empty([3000])\n",
    "trend=np.empty([45])\n",
    "p=scipy.stats.linregress(np.linspace(0,44,45), y=EP_pattern_wfo[5:50], alternative='two-sided')\n",
    "trend=p.intercept+p.slope*np.linspace(0,44,45)\n",
    "\n",
    "from recombinator.block_bootstrap import circular_block_bootstrap\n",
    "\n",
    "# number of replications for bootstraps (number of resampled time-series to generate)\n",
    "B = 3000\n",
    "\n",
    "y_star_cb \\\n",
    "    = circular_block_bootstrap(EP_pattern_wfo[5:50]-trend, \n",
    "                               block_length=2, \n",
    "                               replications=B, replace=True)\n",
    "bootstrap=[]\n",
    "for i in range(0,B):\n",
    "    bootstrap.append(trend+y_star_cb[i,:])\n",
    "\n",
    "for i in range(0,B):\n",
    "    change2[i]=(bootstrap[i][40:45].mean()-bootstrap[i][0:5].mean())/A\n",
    "\n",
    "print(change2.mean())\n",
    "print(change2.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, we need to do the same for each individual member"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of all ensemble members\n",
    "for i in range(0,34):\n",
    "    regridded_2005on[i]=regridded_2005on[i].rename({'y': 'latitude','x': 'longitude'})\n",
    "    regridded_2005on[i]=regridded_2005on[i].assign_coords(latitude=salt_flux_avg_2005on.latitude,longitude=salt_flux_avg_2005on.longitude)\n",
    "    \n",
    "salt_avg_list=[]\n",
    "for i in range(0,34):\n",
    "    salt_avg_list.append(regridded_2005on[i])\n",
    "    \n",
    "climatological_salt_flux_list=[]\n",
    "for i in range(0,34):\n",
    "    climatological_salt_flux_list.append(salt_avg_list[i][0:12*50,:,:].mean('time')) #this is 1920 to 1975\n",
    "    salt_avg_list[i]=salt_avg_list[i][0:12*50,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "EP_pattern_wfo_list=np.empty([34,50])\n",
    "for j in range(0,34):\n",
    "    for i in range(0,50):\n",
    "        EP_pattern_wfo_list[j,i]=np.abs((((salt_avg_list[j][i*12:(i+1)*12,:,:].mean('time')).where(np.sign(wfo.mean('time'))>0))*area.where(area.latitude<65)).sum())+np.abs((((salt_avg_list[j][i*12:(i+1)*12,:,:].mean('time')).where(np.sign(wfo.mean('time'))<0))*area.where(area.latitude<65)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "A=((np.abs(wfo.mean('time')))*area.where(area.latitude<65)).sum() #strength of wfo in this way, 9.99660706e+08 if calculated with regridded or 1.08156723e+09 if not calculated with regridded\n",
    "\n",
    "change=np.empty([3000,34])\n",
    "for j in range(0,34):\n",
    "    trend=np.empty([45])\n",
    "    p=scipy.stats.linregress(np.linspace(0,44,45), y=EP_pattern_wfo_list[j,5:50], alternative='two-sided')\n",
    "    trend=p.intercept+p.slope*np.linspace(0,44,45)\n",
    "\n",
    "    from recombinator.block_bootstrap import circular_block_bootstrap\n",
    "\n",
    "    # number of replications for bootstraps (number of resampled time-series to generate)\n",
    "    B = 3000\n",
    "\n",
    "    y_star_cb \\\n",
    "        = circular_block_bootstrap(EP_pattern_wfo_list[j,5:50]-trend, \n",
    "                                   block_length=2, \n",
    "                                   replications=B, replace=True)\n",
    "    bootstrap=[]\n",
    "    for i in range(0,B):\n",
    "        bootstrap.append(trend+y_star_cb[i,:])\n",
    "\n",
    "    for i in range(0,B):\n",
    "        change[i,j]=(bootstrap[i][40:45].mean()-bootstrap[i][0:5].mean())/A\n",
    "\n",
    "mean_boot_m2=np.empty([34])\n",
    "std_boot_m2=np.empty([34])\n",
    "for j in range(0,34):\n",
    "    mean_boot_m2[j]=change[:,j].mean()\n",
    "    std_boot_m2[j]=change[:,j].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"freshwater_fluxes_integration_mean_boot_2011to2055_new\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(mean_boot_m2, fp)\n",
    "with open(\"freshwater_fluxes_integration_std_boot_2011to2055_new\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(std_boot_m2, fp)\n",
    "\n",
    "ensemble_projection_mean_std=[change2.mean(),change2.std()]\n",
    "with open(\"freshwater_fluxes_ensemble_integration_mean_std_2011to2055_new\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(ensemble_projection_mean_std, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
